{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import clear_output\n",
    "from time import sleep, time\n",
    "from random import randint\n",
    "from requests import get\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re, os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Redeclaring the lists to store data in\n",
    "movie_ids = []\n",
    "names = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []\n",
    "genres = []\n",
    "run_times = []\n",
    "directors = []\n",
    "actors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = 'D:\\\\Data\\\\IMDB\\\\Scrapped'\n",
    "date = datetime.today().strftime('%Y-%m-%d %H-%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get basic movie information using Advanced Title Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_size = 250\n",
    "\n",
    "# Preparing the monitoring of the loop\n",
    "start_time = time()\n",
    "requests = 0\n",
    "year_urls = [str(i) for i in range(2000, 2019)]\n",
    "for year_url in year_urls:\n",
    "    crawl_complete = False\n",
    "    page = 0\n",
    "    while crawl_complete == False:\n",
    "        search_url =('https://www.imdb.com/search/title'\n",
    "                '?title_type=feature'\n",
    "                '&release_date=' + year_url +\n",
    "                '&countries=us&languages=en'\n",
    "                '&count='+ str(page_size) +           \n",
    "                '&start='+ str(page * page_size +  1))\n",
    "        response = get(search_url)\n",
    "        page = page + 1\n",
    "        print(search_url)\n",
    "\n",
    "        # Pause the loop\n",
    "        sleep(randint(2, 4))\n",
    "\n",
    "        # Monitor the requests\n",
    "        requests += 1\n",
    "        elapsed_time = time() - start_time\n",
    "        print('Request:{}; Elapsed:{}; Frequency: {} requests/s'.format(requests, elapsed_time, requests/elapsed_time))\n",
    "        clear_output(wait = True)\n",
    "\n",
    "        # Throw a warning for non-200 status codes\n",
    "        if response.status_code != 200:\n",
    "            warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Select all the 50 movie containers from a single page\n",
    "        mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "        \n",
    "        if len(mv_containers) == 0:\n",
    "            print(\"No container. Crawl Complete for year: \" + str(year_url))\n",
    "            crawl_complete = True\n",
    "            break\n",
    "\n",
    "        # Scrape some attributes for each movie\n",
    "        for container in mv_containers:\n",
    "            # Scrape the movie id\n",
    "            try:\n",
    "                result = re.search('/title/(.*)/(.*)', container.h3.a['href'])\n",
    "                movie_id = result.group(1)  \n",
    "            except:\n",
    "                movie_id = None\n",
    "\n",
    "            if movie_id in movie_ids:\n",
    "                print(\"Movie already exists. Crawl Complete for year: \" + str(year_url))\n",
    "                crawl_complete = True\n",
    "                break\n",
    "            movie_ids.append(movie_id)\n",
    "\n",
    "            # Scrape the name\n",
    "            try:\n",
    "                name = container.h3.a.text\n",
    "            except:\n",
    "                name = None\n",
    "            names.append(name)\n",
    "\n",
    "            # Scrape the year\n",
    "            try:\n",
    "                year_text = container.h3.find('span', class_ = 'lister-item-year').text\n",
    "                result = re.search('\\((\\d{4})\\)$', year_text)\n",
    "                year = result.group(1)  \n",
    "            except:\n",
    "                year = None\n",
    "            years.append(year)\n",
    "\n",
    "            # Scrape the IMDB rating\n",
    "            try:\n",
    "                imdb = float(container.strong.text)\n",
    "            except:\n",
    "                imdb = None\n",
    "            imdb_ratings.append(imdb)\n",
    "\n",
    "            # Scrape the Metascore\n",
    "            try:\n",
    "                m_score = int(container.find('span', class_ = 'metascore').text) \n",
    "            except:\n",
    "                m_score = 0               \n",
    "            metascores.append(m_score)\n",
    "\n",
    "            # Scrape the number of votes\n",
    "            try:\n",
    "                vote = int(container.find('span', attrs = {'name':'nv'})['data-value'])\n",
    "            except:\n",
    "                vote = None\n",
    "            votes.append(vote)\n",
    "\n",
    "            # Scrape the genres\n",
    "            try:\n",
    "                genre = container.find('span', class_ = 'genre').text.strip()\n",
    "            except:\n",
    "                genre = None\n",
    "            genres.append(genre)\n",
    "\n",
    "            # Scrape the run time\n",
    "            try:\n",
    "                runtime = container.find('span', class_ = 'runtime').text\n",
    "                runtime = int(runtime.replace('min', '').strip())\n",
    "            except:\n",
    "                runtime = None\n",
    "            run_times.append(runtime)\n",
    "\n",
    "            # Scrape director and actors\n",
    "            try:\n",
    "                people_div = container.find(\"div\", class_=\"ratings-bar\").find_next_sibling(\"p\").find_next_sibling(\"p\")\n",
    "                people_texts = people_div.text.replace('\\n','').strip().split('|')\n",
    "                \n",
    "                if len(people_texts) >= 1:\n",
    "                    director_text = people_texts[0].strip()\n",
    "                    result = re.search('Director(s?):(.*)', director_text)\n",
    "                    director = result.group(2)\n",
    "\n",
    "                if len(people_texts) >= 2:    \n",
    "                    actors_text = people_texts[1].strip()\n",
    "                    result = re.search('Star(s?):(.*)', actors_text)\n",
    "                    actor = result.group(2)\n",
    "            except:\n",
    "                director = None\n",
    "                actor = None\n",
    "\n",
    "            directors.append(director)\n",
    "            actors.append(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_ratings = pd.DataFrame({'movie_id': movie_ids,\n",
    "                              'name': names,\n",
    "                              'year': years,\n",
    "                              'rating': imdb_ratings,\n",
    "                              'metascore': metascores,\n",
    "                              'votes': votes,\n",
    "                              'genre': genres,\n",
    "                              'runtime': run_times,\n",
    "                              'director': directors,\n",
    "                              'actor' : actors})\n",
    "print(movie_ratings.info())\n",
    "movie_ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data frames to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_ratings.to_csv(os.path.join(output_path, 'movie_ratings_' + date + '.csv'), sep=';', encoding= 'utf8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get budget and revenue info by scrapping individual movie pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"} # to prevent localization in results\n",
    "\n",
    "def make_page_request(url):\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    return urllib.request.urlopen(request)\n",
    "\n",
    "def get_page_html(page):\n",
    "    return BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "def get_release_date(html):\n",
    "    try:\n",
    "        return (html.find(\"h4\", text=\"Release Date:\")).next.next.strip()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_revenue(html):\n",
    "    try:\n",
    "        text = (html.find(\"h4\", text=\"Gross USA:\")).next.next.strip().strip(',')\n",
    "        return int(text[1:].replace(',',''))\n",
    "    except: \n",
    "        return None\n",
    "    \n",
    "def get_revenue_date(html):\n",
    "    try:\n",
    "        return (html.find(\"h4\", text=\"Gross USA:\")).next_sibling.next.text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_budget(html):\n",
    "    try:\n",
    "        text = (html.find(\"h4\", text=\"Budget:\")).next.next.strip().strip(',')\n",
    "        return int(text[1:].replace(',',''))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of movie ids from the previously scrapped movies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = pd.read_csv(os.path.join(output_path, 'movie_ratings_full.csv'), header=0, sep=';', engine='python', encoding= 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request:3525; Elapsed:5538.783479690552; Frequency: 0.6364213392571431 requests/s\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.imdb.com/title/'\n",
    "years = [2016]\n",
    "\n",
    "for year in years:\n",
    "    m_year = m[m.year==year]\n",
    "    movie_ids = m_year['movie_id'].unique()\n",
    "\n",
    "    release_dates = []\n",
    "    revenues = []\n",
    "    revenue_dates = []\n",
    "    budgets = []\n",
    "    skipped_ids = []\n",
    "    \n",
    "    requests = 0\n",
    "    start_time = time()\n",
    "    for m_id in movie_ids:\n",
    "        url = base_url + m_id + '/'\n",
    "        try:\n",
    "            page = make_page_request(url)\n",
    "            html = get_page_html(page)\n",
    "        except:\n",
    "            skipped_ids.append(m_id)\n",
    "            continue\n",
    "\n",
    "        release_date = get_release_date(html)\n",
    "        release_dates.append(release_date)\n",
    "\n",
    "        revenue = get_revenue(html)\n",
    "        revenues.append(revenue)\n",
    "\n",
    "        revenue_date = get_revenue_date(html)\n",
    "        revenue_dates.append(revenue_date)    \n",
    "\n",
    "        budget = get_budget(html)\n",
    "        budgets.append(budget)\n",
    "\n",
    "        requests +=1\n",
    "        if requests % 25 == 0:  \n",
    "            # Pause the loop\n",
    "            sleep(randint(1, 2))\n",
    "\n",
    "            # Monitor the requests\n",
    "            elapsed_time = time() - start_time\n",
    "            print('Request:{}; Elapsed:{}; Frequency: {} requests/s'.format(requests, elapsed_time, requests/elapsed_time))\n",
    "            clear_output(wait = True)\n",
    "    \n",
    "    movie_finance = pd.DataFrame({'movie_id': [item for item in movie_ids if item not in skipped_ids],\n",
    "                                  'release_date': release_dates,\n",
    "                                  'budget': budgets,\n",
    "                                  'revenue': revenues,\n",
    "                                  'revenue_date': revenue_dates})\n",
    "    \n",
    "    movie_finance.to_csv(os.path.join(output_path, 'movie_finance-' + str(year) + '_' + date + '.csv'), \n",
    "                         sep=';', encoding= 'utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_finance = pd.DataFrame({'movie_id': movie_ids,\n",
    "                              'release_date': release_dates,\n",
    "                              'budget': budgets,\n",
    "                              'revenue': revenues,\n",
    "                              'revenue_date': revenue_dates})\n",
    "print(movie_finance.info())\n",
    "movie_finance.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data frames to csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
