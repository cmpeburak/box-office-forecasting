{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burak\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score, KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime, time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Libraries Imported')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_path = 'D:\\\\Data\\\\Box-Office-Forecasting'\n",
    "m = pd.read_csv(os.path.join(i_path, 'movie-master-final.csv'), header=0, sep=';', engine='python', encoding= 'utf8')\n",
    "\n",
    "#target_variable = 'revenue_range'; problem_type = 'MULTICLASS'\n",
    "target_variable = 'is_profitable'; problem_type = 'BINARY'\n",
    "\n",
    "all_features = ['mpaa', 'budget', 'seasonality', 'is_sequel', 'screen_count', 'runtime']\n",
    "yc_features = ['like_ratio', 'polarity_tb', 'polarity_sia']\n",
    "# all_features = all_features + yc_features\n",
    "data = m[all_features + [target_variable]]\n",
    "\n",
    "# like_ratio column has some 'infinity' values, we replace them with one.\n",
    "data = data.replace(np.Inf, 1)\n",
    "\n",
    "# Factorize revenue_range to get numbers instead of labels\n",
    "factor = pd.factorize(data[target_variable])\n",
    "data[target_variable] = factor[0]\n",
    "definitions = factor[1]\n",
    "\n",
    "# Use LabelEncoder to convert textual classifications to numeric. We will use the same encoder later to convert them back.\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "if 'mpaa' in all_features:\n",
    "    data['mpaa'] = encoder.fit_transform(data['mpaa'].astype(str))\n",
    "if 'genre' in all_features:\n",
    "    data['genre'] = encoder.fit_transform(data['genre'].astype(str))\n",
    "\n",
    "# Split columns into independent/predictor variables vs dependent/response/outcome variable\n",
    "X = np.array(data.drop([target_variable], 1))\n",
    "y = np.array(data[target_variable])\n",
    "\n",
    "# Scale the data. We will use the same scaler later for scoring function\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Training - Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=17)\n",
    "\n",
    "# 5 fold stratified cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create file for results\n",
    "date_part = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S')\n",
    "file_name = \"D:\\\\Master\\\\Thesis Related\\\\Results\\\\\" + problem_type + \"_Results_{0}.txt\".format(date_part)\n",
    "f = open(file_name, \"w+\")\n",
    "f.write(\"Model Training has started.\\n\")\n",
    "f.write(\"Number of Features: {0}\\n\".format(len(all_features)))\n",
    "f.write(\"Selected Features: {0}\\n\".format(all_features))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classification_report_df(report):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        report_data.append(float(row_data[3]))\n",
    "    #dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    return report_data\n",
    "\n",
    "# Defining fit_algorithm function\n",
    "def fit_algorithm(alg, X_train, X_test, y_train, y_test, parameters, cv = 5):\n",
    "    \"\"\"\n",
    "    This function will split our dataset into training and testing subsets, fit cross-validated \n",
    "    GridSearch object, test it on the holdout set and return some statistics\n",
    "    \"\"\"\n",
    "    f = open(file_name, \"a\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    f.write(\"============================================================================\\n\")\n",
    "    print(\"Applying {0}...\".format(alg.__class__.__name__))\n",
    "    f.write(\"Applying {0}...\\n\".format(alg.__class__.__name__))\n",
    "\n",
    "    grid = GridSearchCV(alg, parameters, cv = cv, n_jobs=-1, scoring = 'accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    y_pred = grid.predict(X_test)\n",
    "        \n",
    "    # Get Detailed Cross-Validation Scores\n",
    "    d = []\n",
    "    n_param_sets = len(grid.cv_results_['params'])\n",
    "    for i in range(0, n_param_sets):\n",
    "        d.append({'CV Score': grid.cv_results_['mean_test_score'][i], 'Parameter Set': grid.cv_results_['params'][i]})\n",
    "    param_scores = pd.DataFrame(d)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Fitting is complete in {0} \\n\".format(elapsed_time)); f.write(\"Fitting is complete in {0} \\n\\n\".format(elapsed_time));\n",
    "    print(\"Results\"); f.write(\"Results\\n\")\n",
    "    print(\"Best CV Score: {0}\".format(grid.best_score_)); f.write(\"Best CV Score: {0}\\n\".format(grid.best_score_))\n",
    "    print(\"Test Accuracy: {0}\".format(accuracy_score(y_test, y_pred))); print(\"\")\n",
    "    f.write(\"Test Accuracy: {0}\".format(accuracy_score(y_test, y_pred))); f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Confusion Matrix: \\n\")\n",
    "    f.write(str(pd.crosstab(y_test, y_pred, rownames=['Actual Labels'], colnames=['Predicted Labels'])))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"Detailed CV Scores: \\n\")\n",
    "    f.write(str(param_scores)); f.write(\"\\n\\n\");\n",
    "    f.write(\"Classification Report: \\n\")\n",
    "    f.write(metrics.classification_report(y_test, y_pred))\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    classification_report = classification_report_df(report)\n",
    "    values = {\n",
    "        \"model\": alg.__class__.__name__, \n",
    "        \"cv_acc\": np.around(grid.best_score_, decimals=3).astype(str),\n",
    "        \"test_acc\": np.around(accuracy_score(y_test, y_pred), decimals=3).astype(str),\n",
    "        \"test_f1\": np.around(f1_score(y_pred, y_test, average='weighted'),decimals=3).astype(str),\n",
    "        #\"f1_labels\": np.around(f1_score(y_pred, y_test, average='weighted'),decimals=3).astype(str),\n",
    "        \"best_params\": [grid.best_params_],\n",
    "        }\n",
    "    for i in range(0, len(classification_report)):\n",
    "        values[\"f1_\" + str(i)] = classification_report[i]\n",
    "    summary = pd.DataFrame(pd.Series(values)).transpose()\n",
    "    \n",
    "    f.write(\"Algorithm Summary: \\n\")\n",
    "    f.write(str(summary)); f.write(\"\\n\\n\");\n",
    "    f.close()\n",
    "    return summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying DecisionTreeClassifier...\n",
      "Fitting is complete in 3.651630401611328 \n",
      "\n",
      "Results\n",
      "Best CV Score: 0.756152972358955\n",
      "Test Accuracy: 0.7549167927382754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "params = {'max_depth': [4, 5, 6], 'max_features': [4, 5, 6]}\n",
    "model = fit_algorithm(DecisionTreeClassifier(), X_train, X_test, y_train, y_test, params, kf)\n",
    "models = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying KNeighborsClassifier...\n",
      "Fitting is complete in 2.7359657287597656 \n",
      "\n",
      "Results\n",
      "Best CV Score: 0.6925407042786823\n",
      "Test Accuracy: 0.7276853252647504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "params = {'n_neighbors': np.arange(4, 5, 6).tolist()}\n",
    "model = fit_algorithm(KNeighborsClassifier(), X_train, X_test, y_train, y_test, params, kf)\n",
    "models = models.append(model, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SVC...\n",
      "Fitting is complete in 387.0362477302551 \n",
      "\n",
      "Results\n",
      "Best CV Score: 0.7663763725861417\n",
      "Test Accuracy: 0.7715582450832073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10] , 'gamma': [0.001, 0.01, 0.1, 1], \n",
    "              'kernel': ['rbf', 'poly'], 'degree': [2, 3], #degree parameter ignored for kernels other than polynomial.\n",
    "              'class_weight': ['balanced']}\n",
    "model = fit_algorithm(svm.SVC(probability=True), X_train, X_test, y_train, y_test, params, kf)\n",
    "models = models.append(model, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MLPClassifier...\n",
      "Fitting is complete in 6.808453321456909 \n",
      "\n",
      "Results\n",
      "Best CV Score: 0.7656190836804241\n",
      "Test Accuracy: 0.7776096822995462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron\n",
    "params = {'solver': ['adam'] , 'alpha': [0.001], \n",
    "          'hidden_layer_sizes': [(5,3), (4,2), (5,2)], 'activation': ['tanh']}\n",
    "model = fit_algorithm(MLPClassifier(), X_train, X_test, y_train, y_test, params, kf)\n",
    "models = models.append(model, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RandomForestClassifier...\n",
      "Fitting is complete in 38.76346468925476 \n",
      "\n",
      "Results\n",
      "Best CV Score: 0.7731919727375994\n",
      "Test Accuracy: 0.7791225416036308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "params = { 'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth' : [4, 5, 6],\n",
    "              'criterion' :['gini', 'entropy']}\n",
    "model = fit_algorithm(RandomForestClassifier(), X_train, X_test, y_train, y_test, params, kf)\n",
    "models = models.append(model, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying XGBClassifier...\n",
      "Fitting is complete in 113.62389874458313 \n",
      "\n",
      "Results\n",
      "Best CV Score: 0.794774706550549\n",
      "Test Accuracy: 0.8245083207261724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [4, 5, 6]}\n",
    "model = fit_algorithm(XGBClassifier(), X_train, X_test, y_train, y_test, params, kf)\n",
    "models = models.append(model, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Artifical Neural Networks\n",
    "number_of_features = len(all_features)\n",
    "# Create function returning a compiled network\n",
    "def create_network(optimizer='rmsprop'):\n",
    "    \n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                    optimizer=optimizer, # Optimizer\n",
    "                    metrics=['accuracy']) # Accuracy performance metric\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network, verbose=0)\n",
    "# params = { 'epochs':[5, 10], 'batches' : [32, 128, 512], 'momentum' : [0.5, 0.7, 0.9], 'optimizers' : ['rmsprop', 'adam']}\n",
    "params = { 'epochs':[10], 'batches' : [32]}\n",
    "# model = fit_algorithm(neural_network, X_train, X_test, y_train, y_test, params) #no kf\n",
    "# models = models.append(model, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>best_params</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.756</td>\n",
       "      <td>[{'max_depth': 6, 'max_features': 4}]</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.727</td>\n",
       "      <td>[{'n_neighbors': 4}]</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.772</td>\n",
       "      <td>[{'C': 10, 'class_weight': 'balanced', 'degree...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.78</td>\n",
       "      <td>[{'activation': 'tanh', 'alpha': 0.001, 'hidde...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.781</td>\n",
       "      <td>[{'criterion': 'gini', 'max_depth': 6, 'max_fe...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.825</td>\n",
       "      <td>[{'colsample_bytree': 1.0, 'gamma': 1, 'max_de...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model cv_acc test_acc test_f1  \\\n",
       "0  DecisionTreeClassifier  0.756    0.755   0.756   \n",
       "1    KNeighborsClassifier  0.693    0.728   0.727   \n",
       "2                     SVC  0.766    0.772   0.772   \n",
       "3           MLPClassifier  0.766    0.778    0.78   \n",
       "4  RandomForestClassifier  0.773    0.779   0.781   \n",
       "5           XGBClassifier  0.795    0.825   0.825   \n",
       "\n",
       "                                         best_params  f1_0  f1_1  \n",
       "0              [{'max_depth': 6, 'max_features': 4}]  0.71   0.8  \n",
       "1                               [{'n_neighbors': 4}]  0.74  0.71  \n",
       "2  [{'C': 10, 'class_weight': 'balanced', 'degree...  0.72  0.82  \n",
       "3  [{'activation': 'tanh', 'alpha': 0.001, 'hidde...  0.68  0.87  \n",
       "4  [{'criterion': 'gini', 'max_depth': 6, 'max_fe...  0.68  0.86  \n",
       "5  [{'colsample_bytree': 1.0, 'gamma': 1, 'max_de...  0.78  0.86  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Models to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = models.sort_values(by='cv_acc', ascending=False)\n",
    "models.to_excel(file_name.replace('txt', 'xlsx'), encoding= 'utf8', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
